# -*- coding: utf-8 -*-
"""spotify_lyrics_search.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cR5Tsiuafc048QQgtuja_ZeKWpA6_nGZ
"""

from google.colab import files
uploaded = files.upload()

!ls

!unzip "archive (1).zip"

!ls

!find . -name "*.csv"

import pandas as pd
import numpy as np
import re

import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

df = pd.read_csv("./Spotify Million Song Dataset_exported.csv")
print(df.shape)

nltk.download('stopwords')
nltk.download('wordnet')

df = df.rename(columns={
    "song": "track_name",
    "text": "lyrics"
})

df = df[['artist', 'track_name', 'lyrics']]
df.dropna(inplace=True)

print(df.shape)

stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def preprocess(text):
    text = text.lower()
    text = re.sub(r'[^a-zA-Z]', ' ', text)
    tokens = text.split()
    tokens = [lemmatizer.lemmatize(word)
              for word in tokens if word not in stop_words]
    return " ".join(tokens)

df['clean_lyrics'] = df['lyrics'].apply(preprocess)

df.head()

vectorizer = TfidfVectorizer(
    max_features=5000,
    ngram_range=(1, 2)
)

X = vectorizer.fit_transform(df['clean_lyrics'])

print(X.shape)

def predict_song(lyric_snippet):
    lyric_snippet = preprocess(lyric_snippet)
    snippet_vector = vectorizer.transform([lyric_snippet])

    similarity_scores = cosine_similarity(snippet_vector, X)
    best_match_index = similarity_scores.argmax()

    return {
        "Song Title": df.iloc[best_match_index]['track_name'],
        "Artist": df.iloc[best_match_index]['artist']
    }

query = "look at her face it's a wonderful face"
result = predict_song(query)

print("Prediction Result:")
print(result)

def top_k_predictions(lyric_snippet, k=5):
    lyric_snippet = preprocess(lyric_snippet)
    snippet_vector = vectorizer.transform([lyric_snippet])

    similarity_scores = cosine_similarity(snippet_vector, X)[0]
    top_indices = np.argsort(similarity_scores)[-k:][::-1]

    return df.iloc[top_indices][['track_name', 'artist']]

top_k_predictions("we were both young when i first saw you", k=5)

def evaluate_accuracy(n=100):
    correct = 0
    for i in range(n):
        lyrics = df.iloc[i]['lyrics'][:150]
        prediction = predict_song(lyrics)

        if prediction['Song Title'] == df.iloc[i]['track_name']:
            correct += 1

    return (correct / n) * 100

vectorizer = TfidfVectorizer(
    max_features=15000,
    ngram_range=(1, 3),
    min_df=2
)

X = vectorizer.fit_transform(df['clean_lyrics'])

def evaluate_top_k(k=5, n=100):
    correct = 0
    for i in range(n):
        lyrics = df.iloc[i]['lyrics'][:300]
        lyric_vec = vectorizer.transform([preprocess(lyrics)])
        similarity = cosine_similarity(lyric_vec, X)[0]
        top_k = np.argsort(similarity)[-k:]

        if i in top_k:
            correct += 1

    return (correct / n) * 100

print("Top-5 Accuracy:", evaluate_top_k(k=5))

import os
os.listdir()

!cp /content/*.ipynb /content/spotify_lyrics_search.ipynb
!ls